{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nimport torchtext\nimport time\nimport random\nimport pandas as pd\nimport spacy\n","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:27.539712Z","iopub.execute_input":"2022-05-02T05:23:27.540057Z","iopub.status.idle":"2022-05-02T05:23:38.049274Z","shell.execute_reply.started":"2022-05-02T05:23:27.539936Z","shell.execute_reply":"2022-05-02T05:23:38.048526Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Import Required Libraries & Data Loading","metadata":{}},{"cell_type":"code","source":"#importing the training data\ndf=pd.read_csv('../input/imdb-dataset/IMDB Dataset.csv')\nprint(df.shape)\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:38.051017Z","iopub.execute_input":"2022-05-02T05:23:38.051285Z","iopub.status.idle":"2022-05-02T05:23:39.454963Z","shell.execute_reply.started":"2022-05-02T05:23:38.051254Z","shell.execute_reply":"2022-05-02T05:23:39.454244Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation","metadata":{}},{"cell_type":"code","source":"\"\"\"\nsentiment : 0 = negative, 1 = positive \nuse the following to get the sentiment of a sentence :  \nsentiment = 0 if sentiment is negative else 1\n\n\nuse np.where to get the sentiment of a sentence :\n\"\"\"\ndf['sentiment'] = np.where(df['sentiment'] == 'positive', 1, 0)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:39.456115Z","iopub.execute_input":"2022-05-02T05:23:39.457136Z","iopub.status.idle":"2022-05-02T05:23:39.472381Z","shell.execute_reply.started":"2022-05-02T05:23:39.457095Z","shell.execute_reply":"2022-05-02T05:23:39.471679Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:39.474562Z","iopub.execute_input":"2022-05-02T05:23:39.475068Z","iopub.status.idle":"2022-05-02T05:23:39.486912Z","shell.execute_reply.started":"2022-05-02T05:23:39.475030Z","shell.execute_reply":"2022-05-02T05:23:39.486191Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.columns = ['TEXT_COLUMN_NAME', 'LABEL_COLUMN_NAME']","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:39.489731Z","iopub.execute_input":"2022-05-02T05:23:39.489915Z","iopub.status.idle":"2022-05-02T05:23:39.495623Z","shell.execute_reply.started":"2022-05-02T05:23:39.489891Z","shell.execute_reply":"2022-05-02T05:23:39.494888Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nLoad the spacy model and load the English language model from https://spacy.io/usage/models\n\"\"\"\nspacy.load('en_core_web_sm')### ADD YOUR SPACY MODEL HERE ###","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:39.497027Z","iopub.execute_input":"2022-05-02T05:23:39.497331Z","iopub.status.idle":"2022-05-02T05:23:40.234955Z","shell.execute_reply.started":"2022-05-02T05:23:39.497295Z","shell.execute_reply":"2022-05-02T05:23:40.234281Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Text & label Preparation","metadata":{}},{"cell_type":"code","source":"# Define feature processing\n\"\"\"\nDefine the fields for the data.\n\"\"\"\nTEXT = torchtext.legacy.data.Field(tokenize = 'spacy', tokenizer_language = 'en_core_web_sm')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:40.236293Z","iopub.execute_input":"2022-05-02T05:23:40.236712Z","iopub.status.idle":"2022-05-02T05:23:40.825367Z","shell.execute_reply.started":"2022-05-02T05:23:40.236674Z","shell.execute_reply":"2022-05-02T05:23:40.824633Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Define Label processing\nLABEL = torchtext.legacy.data.LabelField(dtype = torch.long)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:40.826615Z","iopub.execute_input":"2022-05-02T05:23:40.826847Z","iopub.status.idle":"2022-05-02T05:23:40.831668Z","shell.execute_reply.started":"2022-05-02T05:23:40.826815Z","shell.execute_reply":"2022-05-02T05:23:40.830821Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nDefine the fields for the data.\n\"\"\"\n\ndf.to_csv('/tmp/moviedata.csv', index = None)\ndf = pd.read_csv('/tmp/moviedata.csv')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:40.833327Z","iopub.execute_input":"2022-05-02T05:23:40.833768Z","iopub.status.idle":"2022-05-02T05:23:44.110713Z","shell.execute_reply.started":"2022-05-02T05:23:40.833732Z","shell.execute_reply":"2022-05-02T05:23:44.109911Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# process the dataset\n\nfield = [('TEXT_COLUMN_NAME', TEXT), ('LABEL_COLUMN_NAME', LABEL)]\ntry: \n  dataset = torchtext.legacy.data.TabularDataset(\n                    path = '/tmp/moviedata.csv', ### ADD YOUR DATASET PATH HERE ###\n                    format = 'csv', ### ADD YOUR DATASET FORMAT HERE ###\n                    skip_header ='True' , ### ADD YOUR SKIP HEADER HERE ### \n                    fields =  field### ADD YOUR FIELDS HERE ### \n  )\nexcept Exception as e:\n  print(e)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:23:44.113917Z","iopub.execute_input":"2022-05-02T05:23:44.114274Z","iopub.status.idle":"2022-05-02T05:24:38.644131Z","shell.execute_reply.started":"2022-05-02T05:23:44.114237Z","shell.execute_reply":"2022-05-02T05:24:38.643379Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"vars(dataset.examples[0])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:38.645569Z","iopub.execute_input":"2022-05-02T05:24:38.645872Z","iopub.status.idle":"2022-05-02T05:24:38.657194Z","shell.execute_reply.started":"2022-05-02T05:24:38.645830Z","shell.execute_reply":"2022-05-02T05:24:38.656527Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Data Split","metadata":{}},{"cell_type":"code","source":"# Split dataset into train and test set\nRANDOM_SEED = 123\ntrain_data, test_data = dataset.split(split_ratio = [0.8, 0.2], random_state = random.seed(RANDOM_SEED))\n\nprint('Length of train data', len(train_data))\nprint('Length of test data', len(test_data))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:38.658573Z","iopub.execute_input":"2022-05-02T05:24:38.658945Z","iopub.status.idle":"2022-05-02T05:24:38.734500Z","shell.execute_reply.started":"2022-05-02T05:24:38.658907Z","shell.execute_reply":"2022-05-02T05:24:38.733663Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"train_data, val_data = train_data.split(split_ratio = [0.85, 0.15], random_state = random.seed(RANDOM_SEED))\n\nprint('Length of train data', len(train_data))\nprint('Length of valid data', len(val_data))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:38.735752Z","iopub.execute_input":"2022-05-02T05:24:38.736002Z","iopub.status.idle":"2022-05-02T05:24:38.794336Z","shell.execute_reply.started":"2022-05-02T05:24:38.735950Z","shell.execute_reply":"2022-05-02T05:24:38.793547Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Data Observation after Tokenization","metadata":{}},{"cell_type":"code","source":"# Look at first traning example\n\nprint(vars(train_data.examples[2000]))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:38.795511Z","iopub.execute_input":"2022-05-02T05:24:38.796230Z","iopub.status.idle":"2022-05-02T05:24:38.801275Z","shell.execute_reply.started":"2022-05-02T05:24:38.796189Z","shell.execute_reply":"2022-05-02T05:24:38.800539Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Build Vocabulary\nVOCABULARY_SIZE = 20000\nTEXT.build_vocab(train_data, max_size = VOCABULARY_SIZE)\nLABEL.build_vocab(train_data)\n\nprint(f'vocabulary size: {len(TEXT.vocab)}')\nprint(f'Label Size: {len(LABEL.vocab)}')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:38.802493Z","iopub.execute_input":"2022-05-02T05:24:38.803109Z","iopub.status.idle":"2022-05-02T05:24:40.543192Z","shell.execute_reply.started":"2022-05-02T05:24:38.803072Z","shell.execute_reply":"2022-05-02T05:24:40.541706Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"a= vars(TEXT.vocab)\nx= a['freqs']\nsorted_freqs=[(l,k) for k,l in sorted([(j,i) for i,j in x.items()], reverse=True)]","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:40.544331Z","iopub.execute_input":"2022-05-02T05:24:40.544597Z","iopub.status.idle":"2022-05-02T05:24:40.885013Z","shell.execute_reply.started":"2022-05-02T05:24:40.544562Z","shell.execute_reply":"2022-05-02T05:24:40.884275Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":" 2 extra value in vocabulary is because added (unknown) and (padding)","metadata":{}},{"cell_type":"code","source":"# Print the most common words: Use the most_common method of the TEXT vocabulary\nmost_common_words = sorted_freqs[0:20]\nprint(most_common_words)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:40.886343Z","iopub.execute_input":"2022-05-02T05:24:40.886585Z","iopub.status.idle":"2022-05-02T05:24:40.894233Z","shell.execute_reply.started":"2022-05-02T05:24:40.886553Z","shell.execute_reply":"2022-05-02T05:24:40.893285Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Token corresponding to first 10 Indices\n\nprint(TEXT.vocab.itos[:20]) #itos = Integer to string","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:40.895957Z","iopub.execute_input":"2022-05-02T05:24:40.896396Z","iopub.status.idle":"2022-05-02T05:24:40.902381Z","shell.execute_reply.started":"2022-05-02T05:24:40.896189Z","shell.execute_reply":"2022-05-02T05:24:40.900873Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation for Batch wise Implimentation","metadata":{}},{"cell_type":"code","source":"# Define Dataloader\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ntrain_loader, valid_loader, test_loader = torchtext.legacy.data.BucketIterator.splits(\n        (train_data, val_data, test_data), ### ADD YOUR SPLIT DATA HERE (Make sure you add it in a tuple) ###\n        batch_size = 128, ### ADD YOUR BATCH SIZE HERE ###\n        sort_within_batch = True, ### ADD YOUR SORT WITHIN BATCH HERE ### \n        sort_key = lambda x : len(x.TEXT_COLUMN_NAME), \n        device = DEVICE\n    )","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:40.904057Z","iopub.execute_input":"2022-05-02T05:24:40.904377Z","iopub.status.idle":"2022-05-02T05:24:40.912713Z","shell.execute_reply.started":"2022-05-02T05:24:40.904342Z","shell.execute_reply":"2022-05-02T05:24:40.912034Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Testing the iterators (note that the number of rows depends on the longest document in the respective batch):\n\nprint('Train')\nfor batch in train_loader:\n    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n    break\n    \nprint('\\nValid:')\nfor batch in valid_loader:\n    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n    break\n    \nprint('\\nTest:')\nfor batch in test_loader:\n    print(f'Text matrix size: {batch.TEXT_COLUMN_NAME.size()}')\n    print(f'Target vector size: {batch.LABEL_COLUMN_NAME.size()}')\n    break","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:40.914238Z","iopub.execute_input":"2022-05-02T05:24:40.914821Z","iopub.status.idle":"2022-05-02T05:24:48.131391Z","shell.execute_reply.started":"2022-05-02T05:24:40.914784Z","shell.execute_reply":"2022-05-02T05:24:48.130665Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Model Building","metadata":{}},{"cell_type":"code","source":"from torch import nn\nclass RNN(nn.Module):\n  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n    super().__init__() #to call the functions in the superclass\n    self.embedding = nn.Embedding(input_dim, embedding_dim) #Embedding layer to create dense vector instead of sparse matrix\n    self.rnn = nn.RNN(embedding_dim, hidden_dim) \n    self.hidden_fc = nn.Linear(hidden_dim,hidden_dim)\n    self.out_fc = nn.Linear(hidden_dim, output_dim)\n    self.dropout = nn.Dropout(0.3)\n  def forward(self, text):\n    embedded = self.embedding(text)\n    output, hidden = self.rnn(embedded)   \n    hidden = self.dropout(hidden[-1,:,:])\n    hidden = F.relu(self.hidden_fc(hidden))\n    return self.out_fc(hidden)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:10:47.463466Z","iopub.execute_input":"2022-05-02T06:10:47.463719Z","iopub.status.idle":"2022-05-02T06:10:47.470764Z","shell.execute_reply.started":"2022-05-02T06:10:47.463691Z","shell.execute_reply":"2022-05-02T06:10:47.470072Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"class RNN1(torch.nn.Module):\n    \n    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n        super().__init__()\n        ### ADD YOUR CODE HERE ###\n        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n        \n        self.rnn = torch.nn.RNN(embedding_dim, hidden_dim)\n        \n        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n        # embedding and LSTM layers\n        \n        ### END YOUR CODE ### \n\n    def forward(self, text):\n        ### ADD YOUR CODE HERE ###\n        # text dim: [sentence length, batch size]\n        # embedded dim: [sentence length, batch size, embedding dim]\n        embedded = self.embedding(text)\n        output, hidden = self.rnn(embedded)   \n        \n        # output dim: [sentence length, batch size, hidden dim]\n        # hidden dim: [1, batch size, hidden dim]\n\n        # hidden dim: [batch size, hidden dim]\n        assert torch.equal(output[-1,:,:],hidden.squeeze(0))\n        \n        ### END YOUR CODE ###\n        #output = \n        return self.fc(hidden.squeeze(0))","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:23:58.542657Z","iopub.execute_input":"2022-05-02T06:23:58.542914Z","iopub.status.idle":"2022-05-02T06:23:58.550642Z","shell.execute_reply.started":"2022-05-02T06:23:58.542884Z","shell.execute_reply":"2022-05-02T06:23:58.549673Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(RANDOM_SEED)\n\nmodel = RNN1(input_dim= len(TEXT.vocab), ### ADD YOUR INPUT DIM HERE. This can be the length of your vocabulary or the embedding dim ###\n            embedding_dim=400, ### ADD YOUR EMBEDDING DIM HERE ###\n            hidden_dim=128, ### ADD YOUR HIDDEN DIM HERE ###\n            output_dim=2  ### ADD NUMBER OF CLASSES HERE ###\n)\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = model.to(DEVICE)\noptimizer =  torch.optim.Adam(model.parameters(), lr=1e-3)### ADD YOUR OPTIMIZER HERE ###","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:28:02.273662Z","iopub.execute_input":"2022-05-02T06:28:02.273918Z","iopub.status.idle":"2022-05-02T06:28:02.363011Z","shell.execute_reply.started":"2022-05-02T06:28:02.273889Z","shell.execute_reply":"2022-05-02T06:28:02.362290Z"},"trusted":true},"execution_count":83,"outputs":[]},{"cell_type":"markdown","source":"# Define Accuracy","metadata":{}},{"cell_type":"code","source":"def compute_accuracy(model, data_loader, device):\n\n    with torch.no_grad():\n\n        correct_pred, num_examples = 0, 0\n\n        for i, (features, targets) in enumerate(data_loader):\n\n            features = features.to(device)\n            targets = targets.float().to(device)\n\n            logits = model(features)\n            _, predicted_labels = torch.max(logits, 1)\n\n            num_examples += targets.size(0)\n            correct_pred += (predicted_labels == targets).sum()\n    return correct_pred.float()/num_examples * 100","metadata":{"execution":{"iopub.status.busy":"2022-05-02T05:24:48.949303Z","iopub.execute_input":"2022-05-02T05:24:48.949564Z","iopub.status.idle":"2022-05-02T05:24:48.956780Z","shell.execute_reply.started":"2022-05-02T05:24:48.949530Z","shell.execute_reply":"2022-05-02T05:24:48.956071Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# Model Run","metadata":{}},{"cell_type":"code","source":"start_time = time.time()\nNUM_EPOCHS = 50\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n#criterion = torch.nn.BCEWithLogitsLoss()\nmodel = model.to(DEVICE)\ncriterion = criterion.to(DEVICE)\nfor epoch in range(NUM_EPOCHS):\n    model.train()\n    for batch_idx, batch_data in enumerate(train_loader):\n        text = batch_data.TEXT_COLUMN_NAME.to(DEVICE)\n        labels = batch_data.LABEL_COLUMN_NAME.to(DEVICE)\n\n        ### FORWARD AND BACK PROP\n                \n        predictions = model(text)\n        \n        loss = F.cross_entropy(predictions, labels)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        \n        optimizer.step()\n        ### UPDATE MODEL PARAMETERS\n        \n        \n        ### LOGGING\n        if not batch_idx % 50:\n            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n                   f'Batch {batch_idx:03d}/{len(train_loader):03d} | '\n                   f'Loss: {loss:.4f}')     \n    with torch.set_grad_enabled(False):\n        print(f'training accuracy: '\n              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n              f'\\nvalid accuracy: '\n              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n        \n    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n    \nprint(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\nprint(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:32:09.983396Z","iopub.execute_input":"2022-05-02T06:32:09.983651Z","iopub.status.idle":"2022-05-02T06:41:05.387865Z","shell.execute_reply.started":"2022-05-02T06:32:09.983621Z","shell.execute_reply":"2022-05-02T06:41:05.387141Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"markdown","source":"# Model Testing","metadata":{}},{"cell_type":"code","source":"import spacy\n\n\nnlp = spacy.blank(\"en\")\n\ndef predict_sentiment(model, sentence):\n\n    model.eval()\n    tokenized = [tok.text for tok in nlp.tokenizer(sentence)]\n    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n    length = [len(indexed)]\n    tensor = torch.LongTensor(indexed).to(DEVICE)\n    tensor = tensor.unsqueeze(1)\n    length_tensor = torch.LongTensor(length)\n    prediction = torch.nn.functional.softmax(model(tensor), dim=1)\n    return prediction[0][1].item()\n\nprint('Probability positive:')\npredict_sentiment(model, \"This is such an awesome movie, I really love it!\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:41:12.754558Z","iopub.execute_input":"2022-05-02T06:41:12.754811Z","iopub.status.idle":"2022-05-02T06:41:12.955525Z","shell.execute_reply.started":"2022-05-02T06:41:12.754781Z","shell.execute_reply":"2022-05-02T06:41:12.954732Z"},"trusted":true},"execution_count":90,"outputs":[]},{"cell_type":"code","source":"print('Probability positive:')\npredict_sentiment(model, \"I really hate this movie. It is really bad and sucks!\")","metadata":{"execution":{"iopub.status.busy":"2022-05-02T06:41:16.146385Z","iopub.execute_input":"2022-05-02T06:41:16.146908Z","iopub.status.idle":"2022-05-02T06:41:16.154922Z","shell.execute_reply.started":"2022-05-02T06:41:16.146870Z","shell.execute_reply":"2022-05-02T06:41:16.154210Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}