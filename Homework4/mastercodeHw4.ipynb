{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import Input,Dense,Flatten\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications.xception import Xception\nfrom tensorflow.keras.applications.xception import preprocess_input\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nimport numpy as np\nfrom glob import glob","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:06.168799Z","iopub.execute_input":"2022-03-29T01:27:06.169632Z","iopub.status.idle":"2022-03-29T01:27:11.742291Z","shell.execute_reply.started":"2022-03-29T01:27:06.169582Z","shell.execute_reply":"2022-03-29T01:27:11.741426Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/csc4851-homework4/birds_400'  \n\nprint(f'Directories: {os.listdir(data_dir)}')\nclasses = os.listdir(data_dir + \"/train\")\nprint(f'Number of classes: {len(classes)}')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:11.744205Z","iopub.execute_input":"2022-03-29T01:27:11.744501Z","iopub.status.idle":"2022-03-29T01:27:12.030625Z","shell.execute_reply.started":"2022-03-29T01:27:11.744465Z","shell.execute_reply":"2022-03-29T01:27:12.028568Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import torchvision.transforms as tt\n\nstats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n\ntrain_tfms = tt.Compose([tt.RandomCrop(224, padding=15, padding_mode='reflect'),\n                         tt.RandomHorizontalFlip(),\n                         tt.ToTensor(),\n                         tt.Normalize(*stats,inplace=True)])   \nvalid_tfms = tt.Compose([tt.ToTensor(),\n                         tt.Normalize(*stats)])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.031498Z","iopub.status.idle":"2022-03-29T01:27:12.031862Z","shell.execute_reply.started":"2022-03-29T01:27:12.031657Z","shell.execute_reply":"2022-03-29T01:27:12.031687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\ntrain_ds = ImageFolder(data_dir+'/train', train_tfms) \nvalid_ds = ImageFolder(data_dir+'/valid', valid_tfms) \ntest_ds = ImageFolder(data_dir+'/test', valid_tfms) ","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.033250Z","iopub.status.idle":"2022-03-29T01:27:12.033716Z","shell.execute_reply.started":"2022-03-29T01:27:12.033451Z","shell.execute_reply":"2022-03-29T01:27:12.033476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset_info(dataset):\n    print(f'Size of dataset: {len(dataset)}')\n    img, label = dataset[0]\n    print(f'Sample-01 Image size: {img.shape}, Label: {label}')\n    print(f'Number of classes: {len(dataset.classes)}\\n\\n')\n\nprint('Train Dataset\\n-----------')\ndataset_info(train_ds)\nprint('Validation Dataset\\n-----------')\ndataset_info(valid_ds)\nprint('Test Dataset\\n-----------')\ndataset_info(test_ds)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.035907Z","iopub.status.idle":"2022-03-29T01:27:12.036342Z","shell.execute_reply.started":"2022-03-29T01:27:12.036104Z","shell.execute_reply":"2022-03-29T01:27:12.036129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfrom cv2 import imread\nimport os\ndef get_counts(dataset_path,dataset_type):\n  all_species_count = len(os.listdir(dataset_path))\n  all_species_names=[]\n  species_image_count=[]\n  all_heights=[]\n  all_widths=[]\n  for i in tqdm(os.listdir(dataset_path)):\n    all_species_names.append(i)\n    species_folder_path = dataset_path + \"/\" + i + \"/\"\n    species_image_count.append(len(os.listdir(species_folder_path)))\n    for j in os.listdir(species_folder_path):\n      filename = species_folder_path + j\n      image = imread(filename)\n      all_heights.append(image.shape[0])\n      all_widths.append(image.shape[1])\n  print()\n  print(f\"Total no. of species in {dataset_type}= {all_species_count}\")\n  return all_species_names,species_image_count,all_heights,all_widths","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.037827Z","iopub.status.idle":"2022-03-29T01:27:12.038494Z","shell.execute_reply.started":"2022-03-29T01:27:12.038239Z","shell.execute_reply":"2022-03-29T01:27:12.038266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_species_names,train_species_image_count,train_images_heights,train_images_widths = get_counts(dataset_path=data_dir+\"/train/\",dataset_type=\"train\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.040109Z","iopub.status.idle":"2022-03-29T01:27:12.040766Z","shell.execute_reply.started":"2022-03-29T01:27:12.040450Z","shell.execute_reply":"2022-03-29T01:27:12.040478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_species_names,val_species_image_count,val_images_heights,val_images_widths = get_counts(dataset_path=data_dir+\"/valid\",dataset_type=\"validation\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.042351Z","iopub.status.idle":"2022-03-29T01:27:12.042838Z","shell.execute_reply.started":"2022-03-29T01:27:12.042571Z","shell.execute_reply":"2022-03-29T01:27:12.042595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_species_names,test_species_image_count,test_images_heights,test_images_widths = get_counts(dataset_path=data_dir+\"/test/\",dataset_type=\"test\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.044448Z","iopub.status.idle":"2022-03-29T01:27:12.045081Z","shell.execute_reply.started":"2022-03-29T01:27:12.044809Z","shell.execute_reply":"2022-03-29T01:27:12.044843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"check = sorted(train_species_names) == sorted(val_species_names) == sorted(test_species_names)\nprint(\"Are all species names same in train, validation & test datasets? -->\",check)","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.046600Z","iopub.status.idle":"2022-03-29T01:27:12.047066Z","shell.execute_reply.started":"2022-03-29T01:27:12.046829Z","shell.execute_reply":"2022-03-29T01:27:12.046853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in train_species_names:\n  if (i not in val_species_names) or (i not in test_species_names):\n    print(i)\n\nprint(\"Performing set difference by subtracting the validation species names from train:-\")\nset(train_species_names).difference(set(val_species_names))\n\nprint(\"Performing set difference by subtracting the train species names from validation:-\")\nset(val_species_names).difference(set(train_species_names))\n\nprint(\"Performing set difference by subtracting the train species names from test:-\")\nset(test_species_names).difference(set(train_species_names))","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.048319Z","iopub.status.idle":"2022-03-29T01:27:12.049320Z","shell.execute_reply.started":"2022-03-29T01:27:12.049033Z","shell.execute_reply":"2022-03-29T01:27:12.049062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.rename(src=data_dir+\"/train/BLACK & YELLOW  BROADBILL\",dst=data_dir+\"/train/BLACK & YELLOW BROADBILL\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.050690Z","iopub.status.idle":"2022-03-29T01:27:12.051520Z","shell.execute_reply.started":"2022-03-29T01:27:12.051255Z","shell.execute_reply":"2022-03-29T01:27:12.051282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.subplot(1,2,1)\nsns.lineplot(data=train_images_heights)\nplt.title(\"all image heights\")\nplt.xlabel(\"Height\")\n\nplt.subplot(1,2,2)\nsns.lineplot(data=train_images_widths)\nplt.title(\"all image widths\")\nplt.xlabel(\"Width\")","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.052957Z","iopub.status.idle":"2022-03-29T01:27:12.053411Z","shell.execute_reply.started":"2022-03-29T01:27:12.053164Z","shell.execute_reply":"2022-03-29T01:27:12.053189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE = [224, 224]","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:27:12.054727Z","iopub.status.idle":"2022-03-29T01:27:12.055399Z","shell.execute_reply.started":"2022-03-29T01:27:12.055136Z","shell.execute_reply":"2022-03-29T01:27:12.055165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/csc4851-homework4/birds_400/train'\nvalid_path = '../input/csc4851-homework4/birds_400/valid'\ntest_path = '../input/csc4851-homework4/birds_400/test'","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:23:27.887957Z","iopub.execute_input":"2022-03-28T21:23:27.888663Z","iopub.status.idle":"2022-03-28T21:23:27.892283Z","shell.execute_reply.started":"2022-03-28T21:23:27.888627Z","shell.execute_reply":"2022-03-28T21:23:27.891529Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"xcept = Xception(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:23:56.412544Z","iopub.execute_input":"2022-03-28T21:23:56.412795Z","iopub.status.idle":"2022-03-28T21:24:03.485155Z","shell.execute_reply.started":"2022-03-28T21:23:56.412767Z","shell.execute_reply":"2022-03-28T21:24:03.484203Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"for layer in xcept.layers:\n  layer.trainable = False\n\nfolders = glob('../input/csc4851-homework4/birds_400/train/*')\nx = Flatten()(xcept.output)\n\nx = layers.Dense(256, 'relu', kernel_initializer='he_normal')(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(0.3)(x)\n\nprediction = Dense(len(folders), activation='softmax')(x)\n\nmodel = Model(inputs=xcept.input, outputs=prediction)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:26:47.244694Z","iopub.execute_input":"2022-03-28T21:26:47.244954Z","iopub.status.idle":"2022-03-28T21:26:47.411490Z","shell.execute_reply.started":"2022-03-28T21:26:47.244925Z","shell.execute_reply":"2022-03-28T21:26:47.410793Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:26:57.031685Z","iopub.execute_input":"2022-03-28T21:26:57.031951Z","iopub.status.idle":"2022-03-28T21:26:57.044418Z","shell.execute_reply.started":"2022-03-28T21:26:57.031921Z","shell.execute_reply":"2022-03-28T21:26:57.043642Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True)\n\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\nvalid_datagen = ImageDataGenerator(rescale = 1./255)\n\ntraining_set = train_datagen.flow_from_directory('../input/csc4851-homework4/birds_400/train',\n                                                 target_size = (224, 224),\n                                                 batch_size = 32,\n                                                 class_mode = 'categorical')\nvalid_set = valid_datagen.flow_from_directory('../input/csc4851-homework4/birds_400/valid',\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')\n\ntest_set = test_datagen.flow_from_directory('../input/csc4851-homework4/birds_400/test',\n                                            target_size = (224, 224),\n                                            batch_size = 32,\n                                            class_mode = 'categorical')","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:27:21.801087Z","iopub.execute_input":"2022-03-28T21:27:21.801972Z","iopub.status.idle":"2022-03-28T21:27:27.967557Z","shell.execute_reply.started":"2022-03-28T21:27:21.801921Z","shell.execute_reply":"2022-03-28T21:27:27.966792Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"r = model.fit(training_set,validation_data=valid_set,epochs=10,steps_per_epoch=len(training_set),validation_steps=len(valid_set))","metadata":{"execution":{"iopub.status.busy":"2022-03-28T21:27:35.096680Z","iopub.execute_input":"2022-03-28T21:27:35.096941Z","iopub.status.idle":"2022-03-28T23:24:54.887312Z","shell.execute_reply.started":"2022-03-28T21:27:35.096912Z","shell.execute_reply":"2022-03-28T23:24:54.886620Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"model.evaluate(test_set)","metadata":{"execution":{"iopub.status.busy":"2022-03-28T23:25:03.810397Z","iopub.execute_input":"2022-03-28T23:25:03.810692Z","iopub.status.idle":"2022-03-28T23:25:14.483684Z","shell.execute_reply.started":"2022-03-28T23:25:03.810658Z","shell.execute_reply":"2022-03-28T23:25:14.483006Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"def plot_accuracies(history):\n    accuracies = [x['val_accuracy'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2022-03-28T23:26:01.070676Z","iopub.execute_input":"2022-03-28T23:26:01.070954Z","iopub.status.idle":"2022-03-28T23:26:01.076984Z","shell.execute_reply.started":"2022-03-28T23:26:01.070924Z","shell.execute_reply":"2022-03-28T23:26:01.076120Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n\nfrom keras.models import load_model\n\nmodel.save('kongh_xception.h5')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T00:31:46.473115Z","iopub.execute_input":"2022-03-29T00:31:46.473869Z","iopub.status.idle":"2022-03-29T00:31:47.411782Z","shell.execute_reply.started":"2022-03-29T00:31:46.473834Z","shell.execute_reply":"2022-03-29T00:31:47.411084Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"accuracies=r.history['accuracy']\n\nplt.plot(accuracies, '-x')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.title('Accuracy vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2022-03-28T23:33:47.008693Z","iopub.execute_input":"2022-03-28T23:33:47.008958Z","iopub.status.idle":"2022-03-28T23:33:47.211574Z","shell.execute_reply.started":"2022-03-28T23:33:47.008930Z","shell.execute_reply":"2022-03-28T23:33:47.210893Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"train_losses = r.history['loss']\nval_losses = r.history['val_loss']\nplt.plot(train_losses, '-bx')\nplt.plot(val_losses, '-rx')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend(['Training', 'Validation'])\nplt.title('Loss vs. No. of epochs');","metadata":{"execution":{"iopub.status.busy":"2022-03-28T23:35:57.418625Z","iopub.execute_input":"2022-03-28T23:35:57.418874Z","iopub.status.idle":"2022-03-28T23:35:57.618346Z","shell.execute_reply.started":"2022-03-28T23:35:57.418846Z","shell.execute_reply":"2022-03-28T23:35:57.617654Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import log_loss\nfrom keras import losses\nfrom glob import glob\nfrom keras.preprocessing import image\ndef prepare(img_path):\n    img = image.load_img(img_path, target_size=(224,224))\n    x = image.img_to_array(img)\n    x = x/224\n    return np.expand_dims(x, axis=0)\n\ncce = losses.CategoricalCrossentropy()","metadata":{"execution":{"iopub.status.busy":"2022-03-29T00:26:25.419099Z","iopub.execute_input":"2022-03-29T00:26:25.419563Z","iopub.status.idle":"2022-03-29T00:26:25.424967Z","shell.execute_reply.started":"2022-03-29T00:26:25.419527Z","shell.execute_reply":"2022-03-29T00:26:25.424032Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"template = [0]*400\nlog_loss = {}\ntest_images = glob(\"/kaggle/input/csc4851-homework4/birds_400/test/\" + \"*/*.jpg\")\n\nfor path in test_images:\n    result = model.predict([prepare(path)])\n    actual_class = path.split('/')[-2]\n    actual_class = \"BLACK & YELLOW  BROADBILL\" if actual_class == \"BLACK & YELLOW BROADBILL\" else actual_class\n    actual_index = classes.index(actual_class)\n    template[actual_index] = 1\n    log_loss_current = cce(template, result[0]).numpy()\n#     print(log_loss_current)\n    if actual_index in log_loss:\n        log_loss[actual_index] += (log_loss_current)/100\n    else:\n        log_loss[actual_index] = (log_loss_current)/100\n    template[actual_index] = 0","metadata":{"execution":{"iopub.status.busy":"2022-03-29T00:26:36.118264Z","iopub.execute_input":"2022-03-29T00:26:36.118519Z","iopub.status.idle":"2022-03-29T00:28:09.581435Z","shell.execute_reply.started":"2022-03-29T00:26:36.118492Z","shell.execute_reply":"2022-03-29T00:28:09.580706Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"log_loss","metadata":{"execution":{"iopub.status.busy":"2022-03-29T00:28:22.269442Z","iopub.execute_input":"2022-03-29T00:28:22.269926Z","iopub.status.idle":"2022-03-29T00:28:22.289435Z","shell.execute_reply.started":"2022-03-29T00:28:22.269890Z","shell.execute_reply":"2022-03-29T00:28:22.288744Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"import csv\nids = list(log_loss.keys())\nvalues = list(log_loss.values())\n\nf = open('Pratyush_submission.csv', 'w')\nwriter = csv.writer(f)\nwriter.writerow(['id','birds'])\nfor index in range(len(ids)):\n    writer.writerow([ids[index],values[index]])","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:39:17.975788Z","iopub.execute_input":"2022-03-29T01:39:17.976140Z","iopub.status.idle":"2022-03-29T01:39:18.038277Z","shell.execute_reply.started":"2022-03-29T01:39:17.976099Z","shell.execute_reply":"2022-03-29T01:39:18.037349Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2022-03-29T01:39:33.447519Z","iopub.execute_input":"2022-03-29T01:39:33.448262Z","iopub.status.idle":"2022-03-29T01:39:34.170690Z","shell.execute_reply.started":"2022-03-29T01:39:33.448220Z","shell.execute_reply":"2022-03-29T01:39:34.169657Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}